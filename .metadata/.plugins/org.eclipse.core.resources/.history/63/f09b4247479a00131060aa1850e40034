/*
 * Copyright 2008 Brian Tanner
 * http://rl-glue-ext.googlecode.com/
 * brian@tannerpages.com
 * http://brian.tannerpages.com
 * 
 *  Licensed under the Apache License, Version 2.0 (the "License");
 *  you may not use this file except in compliance with the License.
 *  You may obtain a copy of the License at
 * 
 *      http://www.apache.org/licenses/LICENSE-2.0
 * 
 *  Unless required by applicable law or agreed to in writing, software
 *  distributed under the License is distributed on an "AS IS" BASIS,
 *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *  See the License for the specific language governing permissions and
 *  limitations under the License.
* 
*  $Revision: 676 $
*  $Date: 2009-02-08 18:15:04 -0700 (Sun, 08 Feb 2009) $
*  $Author: brian@tannerpages.com $
*  $HeadURL: http://rl-glue-ext.googlecode.com/svn/trunk/projects/codecs/Java/examples/skeleton-sample/SkeletonEnvironment.java $
* 
*/

import java.io.BufferedReader;
import java.io.FileNotFoundException;
import java.io.FileReader;
import java.io.IOException;
import java.util.ArrayList;
import java.util.List;
import java.util.Random;
import java.util.Scanner;

import org.rlcommunity.rlglue.codec.EnvironmentInterface;
import org.rlcommunity.rlglue.codec.types.Action;
import org.rlcommunity.rlglue.codec.types.Observation;
import org.rlcommunity.rlglue.codec.types.Reward_observation_terminal;
import org.rlcommunity.rlglue.codec.util.EnvironmentLoader;
import org.rlcommunity.rlglue.codec.taskspec.TaskSpecVRLGLUE3;
import org.rlcommunity.rlglue.codec.taskspec.TaskSpec;
import org.rlcommunity.rlglue.codec.taskspec.ranges.IntRange;
import org.rlcommunity.rlglue.codec.taskspec.ranges.DoubleRange;

/**
 *  A Race car track
 * @author Daniel Toom
 */
public class MonteCarloEnvironment implements EnvironmentInterface {
	private class Position {
		public int x;
		public int y;
		Position(int x, int y) {
			this.x = x;
			this.y = y;
		}
	}
    private int currentPositionX=10;
    private int currentPositionY=10;
    private int currentSpeedX = 0;
    private int currentSpeedY = 0;
    private int maxWidth;
    private int maxHeight;
    private Random rand = new Random();
    //
    private List<Position> startingStates;
    private char[][] track;
    
    private void parseTrack(String filename) {
    	try {
			BufferedReader br = new BufferedReader(new FileReader("track1.txt"));
			String line;
			line = br.readLine();
			Scanner sc = new Scanner(line);
			maxWidth = Integer.parseInt(sc.next());
			maxHeight = Integer.parseInt(sc.next());
			
			track = new char[maxWidth][maxHeight];
			startingStates = new ArrayList<Position>();
			
			int j = maxHeight-1;
			while ((line = br.readLine()) != null) {
				for (int i = 0; i < line.length(); i++) {
					track[i][j] = line.charAt(i);
					if (track[i][j] == 'S') {
						startingStates.add(new Position(i,j));					
					}
				}
				j--;
			}
		} catch (FileNotFoundException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		} catch (IOException e) {
			e.printStackTrace();
		}
    	
    }
    
    public String env_init() {
	
    	parseTrack("track1.txt");
    	System.out.println("Using this track: ");
    	
    	printTrack();
    	System.out.println("With these starting points: ");
    	for(Position p : startingStates) {
    		System.out.println("X: " + p.x + " Y: " + p.y);
    	}
    	currentSpeedX = 0;
    	currentSpeedY = 1;
	//Create a task spec programatically.  This task spec encodes that state, action, and reward space for the problem.
	//You could forgo the task spec if your agent and environment have been created specifically to work with each other
	//ie, there is no need to share this information at run time.  You could also use your own ad-hoc task specification language,
	//or use the official one but just hard code the string instead of constructing it this way.
	    TaskSpecVRLGLUE3 theTaskSpecObject = new TaskSpecVRLGLUE3();
        theTaskSpecObject.setEpisodic();
        theTaskSpecObject.setDiscountFactor(1.0d);
	//Specify that there will be an integer observation [0,20] for the x-position
        theTaskSpecObject.addDiscreteObservation(new IntRange(0, 20));
    //Specify that there will be an integer observation [0,20] for the y-position
        theTaskSpecObject.addDiscreteObservation(new IntRange(0, 20));
    //Specify that there will be an integer observation [0,20] for the x-velocity
        theTaskSpecObject.addDiscreteObservation(new IntRange(0, 20));
    //Specify that there will be an integer observation [0,20] for the y-velocity
        theTaskSpecObject.addDiscreteObservation(new IntRange(0, 20));        
	//Specify that there will be an integer action [1,9], signifying the  
    //requested direction of acceleration (or retardation.)
    //1-3 up				1,4,7 left
    //4-6 no Y-acceleration	2,5,8 no X-acceleration
    //7-9 down				3,6,9 right
        theTaskSpecObject.addDiscreteAction(new IntRange(1, 9));
	//Specify the reward range [-200,0]
        theTaskSpecObject.setRewardRange(new DoubleRange(-200, 0));

        String taskSpecString = theTaskSpecObject.toTaskSpec();
        TaskSpec.checkTaskSpec(taskSpecString);

		//This actual string this makes is:
		//VERSION RL-Glue-3.0 PROBLEMTYPE episodic DISCOUNTFACTOR 1.0 OBSERVATIONS INTS (1 0 20)  ACTIONS INTS (1 0 1)  REWARDS (1 -1.0 1.0)  EXTRA
		
		//This could be simplified a bit if you made it manually to
		//VERSION RL-Glue-3.0 PROBLEMTYPE episodic DISCOUNTFACTOR 1.0 OBSERVATIONS INTS (0 20)  ACTIONS INTS (0 1)  REWARDS (-1.0 1.0)  EXTRA
		return taskSpecString;
    }

	private void printTrack() {
		for(int i = maxHeight-1; i > -1; i--) {
    		for (int j = 0; j < maxWidth; j++) {
    			if (currentPositionX == j && currentPositionY == i)
    				System.out.print("C");
    			else
    				System.out.print("" + track[j][i]);
    		}
    		System.out.println();
    	}
	}

    private void setRandomStartingPoint() {
    	int length = startingStates.size() / 2;
    	int start = rand.nextInt(length);
    	Position p = startingStates.get(start);
    	currentPositionX = p.x;
    	currentPositionY = p.y;
    }
    
    private boolean isInFinishLine() {
    	return false;
    }
    
    private void fillState(int[] stateArray) {
    	stateArray[0]=currentPositionX;
        stateArray[1]=currentPositionY;
        stateArray[2]=currentSpeedX;
        stateArray[3]=currentSpeedY;
    }
    
    public Observation env_start() {
        currentSpeedX = 0;
        currentSpeedY = 1;
        
        setRandomStartingPoint();
        
        Observation returnObservation=new Observation(4,0,0);
        fillState(returnObservation.intArray);
        return returnObservation;
    }

    public Reward_observation_terminal env_step(Action thisAction) {
        boolean episodeOver=false;
        double theReward=0.0d;
        System.out.println("");
        System.out.println("");
        System.out.println("-------------New action received----------------");
        System.out.println("Env received action: " + thisAction.intArray[0]);
        
        changeSpeed(thisAction);
        	
        System.out.println("Speeds are now: X: " + currentSpeedX + 
        		" Y: " + currentSpeedY);
        //Move the car
        moveCar();
        
        printTrack();
        episodeOver = isInFinishLine();
        Observation returnObservation=new Observation(4,0,0);
        fillState(returnObservation.intArray);
        
        Reward_observation_terminal returnRewardObs=new Reward_observation_terminal(theReward,returnObservation,episodeOver);
        return returnRewardObs;
    }
    
    //return -4 if the car tried to move outside of the track
    //also set speed to 1 in a good direction if the car tried to 
    //move outside of the track
    private int moveCar() {
    	int startPositionX = currentPositionX;
    	int startPositionY = currentPositionY;
    	currentPositionX = Math.max(0, 
    			//randomly add 1 to leftward movement
    			Math.min(maxHeight - 1, currentPositionX + currentSpeedX));  
    				//+ ((rand.nextInt(2) == 0) ? 0 : 1)));

    	currentPositionY = Math.max(0, 
    			//randomly add 1 to upward movement
    			Math.min(maxWidth - 1, currentPositionY + currentSpeedY));
    				//+ ((rand.nextInt(2) == 0) ? 0 : 1)));
    	
    	//Did the car try to move outside of the track?
    	int testX = currentPositionX;
    	int testY = currentPositionY;
    	int retval = 0;
    	while (track[testX][testY] == 'x' && testX > startPositionX) {
    		testX--;
    		retval = -4;
    		currentSpeedX = 0;
    		currentSpeedY = 1;
    	}
    	
    	while (track[testX][testY] == 'x' && testY > startPositionY) {
    		retval = -4;
    		testY--;
    		currentSpeedX = 1;
    		currentSpeedY = 0;
    	}
    	if (retval == -4)
    		System.out.println("The car tried to move outside of the track");
    	
    	currentPositionX = testX;
    	currentPositionY = testY;
    	return retval;
    }

	private void changeSpeed(Action thisAction) {

        //Accelerate to the left
        if (thisAction.intArray[0] % 3 == 1) {
        	if (!(currentSpeedX == 1 && currentSpeedY == 0) && currentSpeedX > 0)
        		currentSpeedX--;
        //to the right
        } else if (thisAction.intArray[0] % 3 == 0) {
        	if (!(currentSpeedX == 4))
        		currentSpeedX++;
        }
        
        //downwards
        if (thisAction.intArray[0] > 6 && thisAction.intArray[0] < 10) {
        	if (!(currentSpeedX == 0 && currentSpeedY == 1) && currentSpeedY > 0)
        		currentSpeedY--;
        //upwards
        } else if (thisAction.intArray[0] < 4) {
        	if (!(currentSpeedY == 4))
        		currentSpeedY++;
        }
	}

    public void env_cleanup() {
    }

    public String env_message(String message) {
        if(message.equals("what is your name?"))
            return "my name is skeleton_environment, Java edition!";

	return "I don't know how to respond to your message";
    }
    
   /**
     * This is a trick we can use to make the agent easily loadable.
     * @param args
     */
    public static void main(String[] args){
        EnvironmentLoader theLoader=new EnvironmentLoader(new MonteCarloEnvironment());
        theLoader.run();
    }


}
